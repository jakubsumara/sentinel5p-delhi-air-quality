{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentinel-5P Air Pollution Analysis - Delhi NCR\n",
        "\n",
        "## Complete Analysis Workflow\n",
        "\n",
        "This notebook provides a complete, reproducible workflow for analyzing Sentinel-5P TROPOMI data over Delhi NCR.\n",
        "\n",
        "### Overview\n",
        "- **Time Period:** January 2022 - January 2024 (24 months)\n",
        "- **Pollutants:** NO₂, SO₂, CO, HCHO\n",
        "- **Analysis:** Trajectory analysis, hotspot detection, source attribution\n",
        "\n",
        "### Workflow Steps\n",
        "1. Setup and data verification\n",
        "2. Data processing\n",
        "3. Trajectory analysis (local vs. advected pollution)\n",
        "4. Hotspot analysis\n",
        "5. Visualization\n",
        "6. Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "sys.path.insert(0, str(project_root / 'scripts'))\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "# Project imports\n",
        "import config\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Verify Data Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_data_availability():\n",
        "    \"\"\"Check if required data files exist.\"\"\"\n",
        "    from glob import glob\n",
        "    \n",
        "    required_files = {\n",
        "        'ERA5': 'data/era5/*_daily.nc',\n",
        "        'Sentinel-5P Composites': 'data/processed/*_monthly_composite.nc',\n",
        "        'Time Series': 'data/processed/*_timeseries.csv',\n",
        "        'Classified Data': 'data/processed/*_classified.csv'\n",
        "    }\n",
        "    \n",
        "    print(\"Checking data availability...\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for name, pattern in required_files.items():\n",
        "        files = glob(pattern)\n",
        "        status = \"✓\" if files else \"✗\"\n",
        "        print(f\"{status} {name}: {len(files)} files\")\n",
        "        if files:\n",
        "            for f in sorted(files)[:3]:  # Show first 3\n",
        "                print(f\"    - {os.path.basename(f)}\")\n",
        "            if len(files) > 3:\n",
        "                print(f\"    ... and {len(files) - 3} more\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "\n",
        "check_data_availability()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load and Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load time series data\n",
        "pollutants = ['NO2', 'SO2', 'CO', 'HCHO']\n",
        "time_series = {}\n",
        "\n",
        "for code in pollutants:\n",
        "    file_path = f'data/processed/{code}_timeseries.csv'\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
        "        time_series[code] = df\n",
        "        print(f\"\\n{code} Time Series:\")\n",
        "        print(f\"  Period: {df.index.min()} to {df.index.max()}\")\n",
        "        print(f\"  Mean value: {df['value'].mean():.4f} {config.POLLUTANTS[code]['unit']}\")\n",
        "        print(f\"  Data points: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Trajectory Analysis Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load classified data (local vs. advected)\n",
        "classified_data = {}\n",
        "\n",
        "for code in pollutants:\n",
        "    file_path = f'data/processed/{code}_classified.csv'\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
        "        classified_data[code] = df\n",
        "        \n",
        "        # Summary statistics\n",
        "        local = df[df['regime'] == 'local']\n",
        "        advected = df[df['regime'] == 'advected']\n",
        "        \n",
        "        print(f\"\\n{code} Regime Classification:\")\n",
        "        print(f\"  Local: {len(local)} months ({len(local)/len(df)*100:.1f}%)\")\n",
        "        print(f\"  Advected: {len(advected)} months ({len(advected)/len(df)*100:.1f}%)\")\n",
        "        if len(local) > 0 and len(advected) > 0:\n",
        "            print(f\"  Local mean: {local['value'].mean():.4f} {config.POLLUTANTS[code]['unit']}\")\n",
        "            print(f\"  Advected mean: {advected['value'].mean():.4f} {config.POLLUTANTS[code]['unit']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Key Findings Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"KEY FINDINGS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for code in pollutants:\n",
        "    if code in classified_data:\n",
        "        df = classified_data[code]\n",
        "        local_pct = len(df[df['regime'] == 'local']) / len(df) * 100\n",
        "        \n",
        "        print(f\"\\n{config.POLLUTANTS[code]['name']}:\")\n",
        "        print(f\"  - Local pollution: {local_pct:.1f}% of time\")\n",
        "        print(f\"  - Regional transport: {100-local_pct:.1f}% of time\")\n",
        "        print(f\"  - Mean concentration: {df['value'].mean():.4f} {config.POLLUTANTS[code]['unit']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"For detailed analysis, see:\")\n",
        "print(\"  - outputs/reports/Interpretive_Note_Sentinel5P_Delhi.md\")\n",
        "print(\"  - outputs/maps/ (seasonal anomalies, source attribution)\")\n",
        "print(\"  - outputs/time_series/ (detailed plots)\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
